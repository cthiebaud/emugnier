<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        canvas#echo {
            border: 2px solid red;
            width: 100%;
        }
    </style>
</head>

<body>
    <div id="peaks-container">
        <div id="zoomview-container"></div>
        <div id="overview-container"></div>
    </div>
    <audio id="apfigupahdfpg" controls style="display:block;">
        <source src="par_les_soir_et_caetera.wav" type="audio/mpeg">
    </audio>
    <canvas id="echo">

    </canvas>
</body>

<script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/peaks.js@latest/peaks.min.js"></script>

<script id="blank-template" type="text/x-handlebars-template">
</script>

<script type="module">
    const template = Handlebars.compile(document.getElementById("blank-template").innerHTML);
    $(document).ready(function () {

        (function (Peaks) {
            const options = {
                containers: {
                    zoomview: document.getElementById('zoomview-container'),
                    overview: document.getElementById('overview-container')
                },
                // HTML5 Media element containing an audio track
                mediaElement: document.querySelector('audio'),
                webAudio: {
                    // A Web Audio AudioContext instance which can be used
                    // to render the waveform if dataUri is not provided
                    audioContext: new AudioContext(),

                    // Alternatively, provide an AudioBuffer containing the decoded audio
                    // samples. In this case, an AudioContext is not needed
                    audioBuffer: null,

                    // If true, the waveform will show all available channels.
                    // If false, the audio is shown as a single channel waveform.
                    multiChannel: false
                },
            };

            Peaks.init(options, function (err, peaks) {
                if (err) {
                    console.error('Failed to initialize Peaks instance: ' + err.message);
                    return;
                }
                let stop = true;
                const audio = document.getElementById('apfigupahdfpg');
                const echo = document.getElementById('echo');
                const overview = peaks.views.getView('overview');
                const echoContext = echo.getContext('2d');
                const echoWidth  = 300; // $(echo).width();
                const echoHeight = 100;  // $(echo).height();
                audio.addEventListener('play', () => {
                    stop = false;
                    function step() {
                        echoContext.clearRect(0, 0, $(echo).width(), $(echo).height());
                        $("#overview-container canvas").each((index, canvas) => {
                            echoContext.drawImage(canvas,
                                0, 0, overview._width*2, overview._height*2,
                                0, 0, echoWidth, echoHeight);
                            if (index == 3) {
                                return false;
                            }
                        });
                        if (!stop) {
                            requestAnimationFrame(step);
                        }
                    }
                    requestAnimationFrame(step);
                })
                audio.addEventListener('pause', () => {
                    stop = true;
                })
                audio.addEventListener('stop', () => {
                    stop = true;
                })

            });

        })(peaks);
    });
</script>

</html>